{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP CVII_CNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNjS4EQLx4OcFj6NhXKo5w/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pascuapablo/CEIA/blob/master/scripts/computer_vision/tp/TP_CVII_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8yMzUEED4X3"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as k\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "from random import sample\n",
        "from keras.utils import to_categorical\n",
        "import os\n",
        "from glob import glob\n",
        "from google.colab import drive\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv5wicWlFWDT",
        "outputId": "2a97a8b3-b329-443f-92a9-a2109177967e"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoNYf2X-DgCL"
      },
      "source": [
        "## Funciones Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyJ7QUzzfLjA"
      },
      "source": [
        "def preprocessing_image_ms(x, mean, std):\n",
        "    # loop over image channels\n",
        "    for idx, mean_value in enumerate(mean):\n",
        "        x[..., idx] -= mean_value\n",
        "        x[..., idx] /= std[idx]\n",
        "    return x\n",
        "\n",
        "\n",
        "def categorical_label_from_full_file_name(files, class_indices):\n",
        "  \n",
        "    # file basename without extension\n",
        "    base_name = [os.path.splitext(os.path.basename(i))[0] for i in files]\n",
        "    # class label from filename\n",
        "    base_name = [i.split(\"_\")[0] for i in base_name]\n",
        "    # label to indices\n",
        "    image_class = [class_indices[i] for i in base_name]\n",
        "    # class indices to one-hot-label\n",
        "    return to_categorical(image_class, num_classes=len(class_indices))\n",
        "\n",
        "def hyperspectral_image_generator(files, class_indices, batch_size=32, image_mean=None,\n",
        "                           rotation_range=0, shear_range=0, scale_range=1,\n",
        "                           transform_range=0, horizontal_flip=False,\n",
        "                           vertical_flip=False, crop=False, crop_size=None, filling_mode='edge',\n",
        "                           speckle_noise=None):\n",
        "    \n",
        "\n",
        "    while True:\n",
        "        # select batch_size number of samples without replacement\n",
        "        batch_files = sample(files, batch_size)\n",
        "        # get one_hot_label\n",
        "        batch_Y = categorical_label_from_full_file_name(batch_files,\n",
        "                                                        class_indices)\n",
        "        # array for images\n",
        "        batch_X = []\n",
        "        # loop over images of the current batch\n",
        "        for idx, input_path in enumerate(batch_files):\n",
        "            normalization_factor =  0.0001\n",
        "            image = np.array(imread(input_path), dtype=np.int16)\n",
        "            image = image * normalization_factor\n",
        "            \n",
        "            # Imprime las imagenes que esta analizando\n",
        "            # print(input_path, image.shape, image.max())\n",
        "            \n",
        "            if image_mean is not None:\n",
        "                mean_std_data = np.loadtxt(image_mean, delimiter=',')\n",
        "                image = preprocessing_image_ms(image, mean_std_data[0], mean_std_data[1])\n",
        "            # process image\n",
        "           \n",
        "            # put all together\n",
        "            batch_X += [image]\n",
        "        # convert lists to np.array\n",
        "        X = np.array(batch_X)\n",
        "        Y = np.array(batch_Y)\n",
        "       \n",
        "        yield(X, Y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUjrqHIHDk0Z"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3O83WSyfWhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac92f58-ccb6-4d8b-c560-5f7dfad525b1"
      },
      "source": [
        "# Carpeta del drive donde estan las imagenes\n",
        "folderPath = '/content/drive/MyDrive/Cursos/CEIA/Computer Vision II/imagenes_tp'\n",
        "\n",
        "\n",
        "\n",
        "files = np.random.permutation(glob(folderPath + \"/**/*.tif\"))\n",
        "\n",
        "train_validation_split_index = np.ceil((len(files) * 0.7)).astype(int)\n",
        "\n",
        "files_train = files[0: train_validation_split_index]\n",
        "files_val = files[train_validation_split_index:]\n",
        "\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "FILES_AMOUNT = len(files_train)\n",
        "EPOCHS = 15\n",
        "\n",
        "\n",
        "\n",
        "image_class = [f.split('/')[-1].split(\"_\")[0] for f in files]\n",
        "classes = {}\n",
        "weight_clases = {}\n",
        "for i,c in enumerate(np.unique(image_class)):\n",
        "  classes[c]=i\n",
        "\n",
        "  weight_clases[c]= np.sum(1 if (\"/\" + c + '/') in f else 0 for f in files)\n",
        "\n",
        "\n",
        "\n",
        "train_generator = hyperspectral_image_generator(\n",
        "    files_train.tolist(),\n",
        "    class_indices = classes,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "\n",
        "val_generator = hyperspectral_image_generator(\n",
        "    files_val.tolist(),\n",
        "    class_indices = classes,\n",
        "    batch_size=1\n",
        ")\n",
        "\n",
        "\n",
        "CLASSES_COUNT = len(classes)\n",
        "\n",
        "weight_clases\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': 5,\n",
              " 'B': 6,\n",
              " 'G': 1,\n",
              " 'M': 210,\n",
              " 'N': 78,\n",
              " 'P': 54,\n",
              " 'R': 6,\n",
              " 'S': 342,\n",
              " 'T': 1,\n",
              " 'U': 12,\n",
              " 'X': 18,\n",
              " 'aa': 2,\n",
              " 'm': 4,\n",
              " 's': 87}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qaej6Tk5EY6B",
        "outputId": "92ffb59f-2648-403e-ff23-0ec7f55ba348"
      },
      "source": [
        "\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu', padding ='same',input_shape=(16,16,13)))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128, (3,3),  padding ='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(256, (3,3),  padding ='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(CLASSES_COUNT, activation='softmax'))\n",
        "\n",
        "# compilar el modelo con binary_crossentropy y optimizador RMSprop con\n",
        "# learning rate 1e-4, la m√©trica a usar es la accuracy (acc)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=1e-4),\n",
        "              metrics=[ CategoricalAccuracy(name=\"accuracy\")] )\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 16, 16, 64)        7552      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 32)                32800     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 14)                462       \n",
            "=================================================================\n",
            "Total params: 409,838\n",
            "Trainable params: 409,838\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BWfajUJEhZK",
        "outputId": "de36d3b5-fceb-423d-eeb0-ef0624748c4d"
      },
      "source": [
        "model.fit_generator(\n",
        "            train_generator,\n",
        "            epochs=EPOCHS,\n",
        "            steps_per_epoch=FILES_AMOUNT/BATCH_SIZE,\n",
        "            validation_data=val_generator,\n",
        "            validation_steps=5           \n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "37/36 [==============================] - 2s 42ms/step - loss: 1.2591 - accuracy: 0.6064 - val_loss: 1.0287 - val_accuracy: 0.6000\n",
            "Epoch 2/15\n",
            "37/36 [==============================] - 2s 42ms/step - loss: 1.1977 - accuracy: 0.6182 - val_loss: 0.6020 - val_accuracy: 1.0000\n",
            "Epoch 3/15\n",
            "37/36 [==============================] - 2s 41ms/step - loss: 1.0946 - accuracy: 0.6402 - val_loss: 0.5736 - val_accuracy: 0.8000\n",
            "Epoch 4/15\n",
            "37/36 [==============================] - 2s 41ms/step - loss: 1.2741 - accuracy: 0.6064 - val_loss: 1.0311 - val_accuracy: 0.8000\n",
            "Epoch 5/15\n",
            "37/36 [==============================] - 2s 42ms/step - loss: 1.1577 - accuracy: 0.6605 - val_loss: 0.8503 - val_accuracy: 0.8000\n",
            "Epoch 6/15\n",
            "37/36 [==============================] - 2s 42ms/step - loss: 1.1400 - accuracy: 0.6470 - val_loss: 1.0792 - val_accuracy: 0.6000\n",
            "Epoch 7/15\n",
            "37/36 [==============================] - 2s 42ms/step - loss: 1.1515 - accuracy: 0.6436 - val_loss: 1.4260 - val_accuracy: 0.4000\n",
            "Epoch 8/15\n",
            "37/36 [==============================] - 2s 42ms/step - loss: 1.0909 - accuracy: 0.6605 - val_loss: 0.6225 - val_accuracy: 0.8000\n",
            "Epoch 9/15\n",
            "37/36 [==============================] - 2s 41ms/step - loss: 1.0727 - accuracy: 0.6672 - val_loss: 0.9562 - val_accuracy: 0.4000\n",
            "Epoch 10/15\n",
            "37/36 [==============================] - 2s 43ms/step - loss: 1.1753 - accuracy: 0.6486 - val_loss: 1.3894 - val_accuracy: 0.6000\n",
            "Epoch 11/15\n",
            "37/36 [==============================] - 2s 41ms/step - loss: 1.0341 - accuracy: 0.7061 - val_loss: 2.7526 - val_accuracy: 0.2000\n",
            "Epoch 12/15\n",
            "37/36 [==============================] - 2s 41ms/step - loss: 0.9822 - accuracy: 0.7128 - val_loss: 0.8866 - val_accuracy: 0.8000\n",
            "Epoch 13/15\n",
            "37/36 [==============================] - 1s 39ms/step - loss: 1.0082 - accuracy: 0.7078 - val_loss: 0.5594 - val_accuracy: 0.8000\n",
            "Epoch 14/15\n",
            "37/36 [==============================] - 1s 39ms/step - loss: 1.0373 - accuracy: 0.7078 - val_loss: 1.0034 - val_accuracy: 0.6000\n",
            "Epoch 15/15\n",
            "37/36 [==============================] - 1s 39ms/step - loss: 1.0174 - accuracy: 0.6706 - val_loss: 0.9164 - val_accuracy: 0.8000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6de0cac18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I-3eKgY2jYB"
      },
      "source": [
        "y_predict = model.predict_generator(val_generator,steps=len(files_val))\n",
        "\n",
        "y_true = categorical_label_from_full_file_name(files_val,classes)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPhgaPMMBkKH",
        "outputId": "2b34ceac-7ca3-4fa5-cd9b-392d76d5084e"
      },
      "source": [
        "y_true_index = [ i.argmax() for i in y_true]\n",
        "y_predict_index = [ i.argmax() for i in y_predict]\n",
        "\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "\n",
        "\n",
        "score = balanced_accuracy_score(y_true_index, y_predict_index)\n",
        "\n",
        "b = (( np.array(y_true_index) - np.array(y_predict_index)))\n",
        "c =(b == 0).sum() /len(y_true_index)\n",
        "print(c,score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3076923076923077 0.082109447444499\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}